{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n",
    "\n",
    "## Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = Path('Resources/LoanStats_2019Q1.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preview the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe for any null or non numeric feature values pre clean\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe for any non numeric feature values pre clean\n",
    "df.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return columns from dataframe for any null or non numeric feature values pre clean\n",
    "df.select_dtypes(include='object').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the not numerical data in the feature columns ready for modelling                               \n",
    "clean_df = pd.get_dummies(df, columns=[\"home_ownership\",\"verification_status\",\"issue_d\",\"pymnt_plan\",\"initial_list_status\",\"next_pymnt_d\",\"application_type\",\"hardship_flag\",\"debt_settlement_flag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe for any null or non numeric feature values post clean\n",
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "X = clean_df.copy()\n",
    "\n",
    "# Dropping homeowner and loan_statis columns\n",
    "X.drop([\"loan_status\"], axis=1, inplace=True)\n",
    "\n",
    "# Create our target\n",
    "y = clean_df[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of our target values\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the X and y into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, \n",
    "                                                   y, \n",
    "                                                   random_state=1, \n",
    "                                                   stratify=y)\n",
    "# Examine X and y testing and training set shapes\n",
    "#X_train.shape\n",
    "#X_test.shape\n",
    "#y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "Scale the training and testing data using the `StandardScaler` from `sklearn`. Remember that when scaling the data, you only scale the features data (`X_train` and `X_testing`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "# When fitting scaling functions, only train on the training dataset\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and testing data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learners\n",
    "\n",
    "In this section, you will compare two ensemble algorithms to determine which algorithm results in the best performance. You will train a Balanced Random Forest Classifier and an Easy Ensemble classifier . For each algorithm, be sure to complete the folliowing steps:\n",
    "\n",
    "1. Train the model using the training data. \n",
    "2. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "3. Display the confusion matrix from sklearn.metrics.\n",
    "4. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "5. For the Balanced Random Forest Classifier only, print the feature importance sorted in descending order (most important feature to least important) along with the feature score\n",
    "\n",
    "Note: Use a random state of 1 for each algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "brf_model = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "brf_model.fit(X_train_scaled, y_train)\n",
    "y_pred = brf_model.predict(X_test_scaled)\n",
    "brf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67209249388625"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   30,    57],\n",
       "       [   11, 17107]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "  high_risk       0.73      0.34      1.00      0.47      0.59      0.32        87\n",
      "   low_risk       1.00      1.00      0.34      1.00      0.59      0.37     17118\n",
      "\n",
      "avg / total       1.00      1.00      0.35      1.00      0.59      0.37     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.08758715176950288, 'total_rec_prncp'),\n",
       " (0.07770386368390605, 'total_pymnt'),\n",
       " (0.0668123203275906, 'total_pymnt_inv'),\n",
       " (0.06459395200819652, 'last_pymnt_amnt'),\n",
       " (0.05039235474187962, 'total_rec_int'),\n",
       " (0.02136336078215045, 'out_prncp_inv'),\n",
       " (0.021208274791883988, 'installment'),\n",
       " (0.01897321061620999, 'out_prncp'),\n",
       " (0.01626915816044429, 'dti'),\n",
       " (0.015749878157203166, 'total_bal_ex_mort'),\n",
       " (0.015582867584390167, 'mo_sin_old_rev_tl_op'),\n",
       " (0.01453797246616538, 'total_rec_late_fee'),\n",
       " (0.014132027435623728, 'avg_cur_bal'),\n",
       " (0.014110841747070672, 'max_bal_bc'),\n",
       " (0.013983181108134525, 'revol_bal'),\n",
       " (0.013859883554018463, 'mo_sin_old_il_acct'),\n",
       " (0.013841987813126443, 'bc_util'),\n",
       " (0.01380522133571516, 'loan_amnt'),\n",
       " (0.013366877033695225, 'bc_open_to_buy'),\n",
       " (0.013079969483511075, 'annual_inc'),\n",
       " (0.012834266696655773, 'total_acc'),\n",
       " (0.012790627140451788, 'il_util'),\n",
       " (0.012705207421490807, 'total_bc_limit'),\n",
       " (0.012676428851197146, 'int_rate'),\n",
       " (0.012558618571945594, 'tot_cur_bal'),\n",
       " (0.012407210326579583, 'tot_hi_cred_lim'),\n",
       " (0.012398174594794873, 'mths_since_rcnt_il'),\n",
       " (0.012358412184315656, 'total_rev_hi_lim'),\n",
       " (0.011675072737656444, 'total_il_high_credit_limit'),\n",
       " (0.010767488353293928, 'total_bal_il'),\n",
       " (0.010043816389523988, 'all_util'),\n",
       " (0.009935465769342866, 'num_il_tl'),\n",
       " (0.009910248933059458, 'mo_sin_rcnt_rev_tl_op'),\n",
       " (0.00973855283136764, 'num_sats'),\n",
       " (0.00948283314501789, 'mths_since_recent_bc'),\n",
       " (0.00924470927869754, 'mths_since_recent_inq'),\n",
       " (0.009211158824857414, 'total_cu_tl'),\n",
       " (0.009073630160678137, 'num_actv_bc_tl'),\n",
       " (0.008977861630304465, 'mo_sin_rcnt_tl'),\n",
       " (0.008894174646576141, 'num_rev_accts'),\n",
       " (0.008766250981558726, 'num_rev_tl_bal_gt_0'),\n",
       " (0.008580834952836973, 'num_op_rev_tl'),\n",
       " (0.008464264960055935, 'num_actv_rev_tl'),\n",
       " (0.008279600094677415, 'open_acc'),\n",
       " (0.00802090155592144, 'num_bc_tl'),\n",
       " (0.007705120140848875, 'pct_tl_nvr_dlq'),\n",
       " (0.007577541846679696, 'issue_d_Mar-2019'),\n",
       " (0.007457052966487497, 'inq_last_12m'),\n",
       " (0.007308971777164099, 'open_rv_24m'),\n",
       " (0.007070812793522802, 'acc_open_past_24mths'),\n",
       " (0.007050124495760758, 'mort_acc'),\n",
       " (0.00697872754852336, 'open_acc_6m'),\n",
       " (0.006865825474764245, 'open_il_24m'),\n",
       " (0.006481986112251835, 'open_act_il'),\n",
       " (0.0064570958583910175, 'num_bc_sats'),\n",
       " (0.006452654932370651, 'inq_fi'),\n",
       " (0.006085432972766774, 'num_tl_op_past_12m'),\n",
       " (0.005976109970216228, 'percent_bc_gt_75'),\n",
       " (0.005751832483774414, 'issue_d_Jan-2019'),\n",
       " (0.005221985092221458, 'open_rv_12m'),\n",
       " (0.005039073197006972, 'inq_last_6mths'),\n",
       " (0.004640461223951516, 'next_pymnt_d_May-2019'),\n",
       " (0.004599174818315894, 'issue_d_Feb-2019'),\n",
       " (0.004177936805083914, 'open_il_12m'),\n",
       " (0.003920231276321782, 'delinq_2yrs'),\n",
       " (0.0038318417123820985, 'next_pymnt_d_Apr-2019'),\n",
       " (0.003727515682071744, 'num_accts_ever_120_pd'),\n",
       " (0.003290114707899756, 'tot_coll_amt'),\n",
       " (0.002665519700728709, 'pub_rec_bankruptcies'),\n",
       " (0.002413395873833711, 'pub_rec'),\n",
       " (0.002231081914469637, 'verification_status_Verified'),\n",
       " (0.0020973053912728113, 'verification_status_Source Verified'),\n",
       " (0.001893608337031974, 'verification_status_Not Verified'),\n",
       " (0.0017991529473260516, 'home_ownership_OWN'),\n",
       " (0.0017207660879790647, 'application_type_Joint App'),\n",
       " (0.0015076593321890729, 'num_tl_90g_dpd_24m'),\n",
       " (0.0014687455508103195, 'home_ownership_RENT'),\n",
       " (0.0013220967906772089, 'initial_list_status_w'),\n",
       " (0.0012732251618991978, 'collections_12_mths_ex_med'),\n",
       " (0.0012324717732577588, 'home_ownership_MORTGAGE'),\n",
       " (0.0012008537707003815, 'application_type_Individual'),\n",
       " (0.0011797073729113887, 'initial_list_status_f'),\n",
       " (0.0011615910342126616, 'home_ownership_ANY'),\n",
       " (0.00041502943864676537, 'chargeoff_within_12_mths'),\n",
       " (0.0, 'tax_liens'),\n",
       " (0.0, 'recoveries'),\n",
       " (0.0, 'pymnt_plan_n'),\n",
       " (0.0, 'policy_code'),\n",
       " (0.0, 'num_tl_30dpd'),\n",
       " (0.0, 'num_tl_120dpd_2m'),\n",
       " (0.0, 'hardship_flag_N'),\n",
       " (0.0, 'delinq_amnt'),\n",
       " (0.0, 'debt_settlement_flag_N'),\n",
       " (0.0, 'collection_recovery_fee'),\n",
       " (0.0, 'acc_now_delinq')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importances = brf_model.feature_importances_\n",
    "sorted(zip(brf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EasyEnsembleClassifier(n_estimators=100, random_state=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Classifier\n",
    "ee_model = EasyEnsembleClassifier(n_estimators=100, random_state=1)\n",
    "ee_model.fit(X_train_scaled, y_train)\n",
    "y_pred = ee_model.predict(X_test_scaled)\n",
    "ee_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9254565671948463"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   79,     8],\n",
       "       [  978, 16140]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "  high_risk       0.07      0.91      0.94      0.14      0.93      0.85        87\n",
      "   low_risk       1.00      0.94      0.91      0.97      0.93      0.86     17118\n",
      "\n",
      "avg / total       0.99      0.94      0.91      0.97      0.93      0.86     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Questions\n",
    "\n",
    "1. Which model had the best balanced accuracy score?\n",
    "\n",
    "    YOUR ANSWER HERE.\n",
    "\n",
    "2. Which model had the best recall score?\n",
    "\n",
    "    YOUR ANSWER HERE.\n",
    "\n",
    "3. Which model had the best geometric mean score?\n",
    "\n",
    "    YOUR ANSWER HERE.\n",
    "\n",
    "4. What are the top three features?\n",
    "\n",
    "    YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
